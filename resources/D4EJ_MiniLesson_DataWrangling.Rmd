---
title: 'D4EJ Tutorials : Data Wrangling'
author: "Samantha Sambado"
date: "2023-06-05"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

#### Welcome to Data for Enviornmental Judtice (D4EJ) mini-lessons!

The purpose of these computer labs are to give you hands-on experience with importing and manipulating data in the **RStudio environment**. This may be your first time coding or hearing about R, which is *really exciting* & will sometimes be frustrating; but that's totally normal.

### Outline

+ The Big Picture  

+ Tidyverse - yes again, you can't get enough of this stuff!

+ Exercises    

+ How to Google when you don't know how to do the exercises 


### The Big Picture

#### 1. Data + R = a tool to tell a story 
So much data exists in our world! With R, you have the ability to use that data to ask and answer questions. There are many ways to tell a story, but there are some general guidelines on how to build that story:

+ First ask yourself, what is your outcome of interest - your **dependent** variable 'y'?

+ Then ponder, what is influencing your outcome of interest - your **independent** variable 'x'? 


Some questions you may have that R could theoretically solve for you:

+ Does soil type (**independent**) influence tree height (**dependent**)?

+ Does distance from ocean (**independent**) influence rent costs (**dependent**)?

+ Do twitter mentions (**independent**) influence cryptocurrency value (**dependent**)?


#### 2. Your type of data determines how you can shape your story


##### Main groups

+ **Numerical** --> numbers, duh.

+ **Categorical** --> characteristics, like words.



##### Subgroups

+ **Continuous** --> numbers can take on **any** value

  + *example: height, weight, temperature*
  

+ **Discrete** --> numbers or words can only be **certain** values

  + *example: days of the week, # of kids in a class, pet type*
  
  
  
##### Sub-subgroup of discrete

+ **Nominal** --> discrete units with no order

  + *example: languages, countries, gender*
  
  
+ **Ordinal** --> discrete unites with order

  + *example: months of year, levels of education, TA reviews*
  


#### 3. Once you understand your story, then you can hop into data wrangling - yeehaw.

##### Note

+ Data wrangling will require a lot of wrangling




+ Be prepared to try **a lot** of different stuff 



+ Off the top of your head, you only need to know how to google. 




#### Okay, end philosophical ramble. Let's get started. 



### Tidyverse - yes again, you can't get enough of this stuff!



### Background

tidyverse isn't a package, it's a collection of packages

+ *just like universities are made up of colleges that have specific functions*

#### Rules

+ Each **variable** has its own **column**

+ Each **observation** has its own **row**

+ Each **value** has its own **cell**



#### Additional Resources - check 'em out!
*Note: Script for this workshop was largely taken from these sources*

[Basic Tidyverse Concepts](https://homerhanumat.github.io/r-notes/tidyverse-concepts.html)


[Tidyverse with animations](https://www.garrickadenbuie.com/project/tidyexplain/)


[Tidyverse-cookbook](https://rstudio-education.github.io/tidyverse-cookbook/tidy.html)


[YaRrr! The pirateâ€™s guide to R -- chapter 10.4](https://bookdown.org/ndphillips/YaRrr/dplyr.html)


#### The Set Up
```{r setup, include=FALSE, message = FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE) # this means

### basic command line structure ###
    # object <- function(argument)

```


1. Libraries needed for this workshop
```{r, message = FALSE}

# remember, install.packages("PACAKGE") then library(PACKAGE)
  ## Note: quotations for install.packages(), no quotations for libary()

# you only need to install a package once to call the library

# after you install.packages(), then hashtag # install.packages()

# install.packages("tidyverse")
library(tidyverse) # package to use tidyverse functions

# install.packages("devtools")
library("devtools") # package to call data from

# specific githubs you will call information from
devtools::install_github("homerhanumat/bcscr")
devtools::install_github("homerhanumat/tigerData")


# install.packages("mosaicData")
library(mosaicData) # package to call data from

```

2. Data needed for this workshop
```{r}
## we will be using online datasets so we don't have to worry about file paths for now. There are many ways to call in data from the internet compared to when you are uploading a dataset from your own Rproj

# data from github for examples

# dataset 1 for examples
survey <- bcscr::m111survey # comes from homerhanumat github

# dataset 2 for examples
data(CPS85) # comes from package `mosaicData`

# dataset 3 for exercise 
data("flights", package = "nycflights13") # data built into R for exercises

```

### Basics of Tidyverse functions

#### 1. pipe operator `%>` : chains function together

```{r pipe operator}
# using pipe operator
"hello" %>% rep(times = 4)

# without pipe operator
rep("hello", times = 4)
```


#### 2. tibble : type of dataframe suited for tidyverse

```{r tibble}
# dataframe
class(survey) # dataframe 

# convert dataframe to tibble
survey <- as_tibble(survey)
class(survey)

```


#### 3. dplyr package : tool for data manipulation

+ a. `filter()` and `select()` for sub-setting

+ b. `mutate()` for transforming variables

+ c. `group_by()` and `summarise()` for numerical summaries

+ d. `fivenum()` for all 5 summaries 


Example a: **`filter()` and `select()`** to chose optimal observations & variables
```{r filter and select}
# we will use dataset survey from homerhanumat github that are the results of a survey of MAT 111 students at Georgetown College

# always look at your new dataset 
  # dim(survey)
  # head(survey)


## okay let's wrangle 


# usually filter() and select() are your first arguments when you get a dataset
survey %>% # call tibble
  filter((sex == "male" & height > 70) | (sex == "female" & height < 55)) %>% # filter picks out rows/observations ## we're selecting observations that are men > 70 in tall AND women < 55 in tall
  select(sex, height, fastest) # selects picks out columns/variables
# let's leave out columns/variables ; use `-`
survey %>%
  select(-ideal_ht, -love_first) # still have lots of columns left!
# want to see how many observations you have left post subsetting?
survey %>%
  filter(love_first == "yes" & fastest > 120) %>%
  nrow() # count the rows/observations left

```

Example b: **`mutate()`** to transform variables
```{r mutate}
# keep new variable name on LEFT side of `=`
# keep function on RIGHT side of `=` that depends on the current value in the tibble


survey %>%
  mutate(dareDevil = fastest > 125) %>% # make new column/variable called dareDevil ## this will provide TRUE (> 125) /FALSE (< 125) for each observation with regards to its fastest value
  select(sex, fastest, dareDevil) # select desired variables
# You can double dip mutations within one line of code
survey %>%
  mutate(dareDevil = fastest > 125, 
         speedKmHR = fastest * 1.60934) %>% # made two new variables/columns based on previous data in column 'fastest')
  ggplot(aes(x = dareDevil, y = GPA)) + # plot these new variable values
  geom_boxplot(fill = 'burlywood', outlier.alpha = 0) + # using boxplot to visualize datat
  geom_jitter(width = 0.2) # avoid points overlapping and making them a certain size
  
```

Example c:  **`group_by()` and `summarise()`** to generate numerical summaries 

```{r group_by and summarise}
# we will use dataset CPS85 from the MosaicData package that is data from the 1985 Current Population Survey

# always look at your new dataset 
  # dim(CPS85)
  # head(CPS85)


# okay let's wrangle 


CPS85 %>% # tibble that comes from the `mosaicData`
  group_by(sex) %>% # divide observations based on their values/observations in the variable 
  summarize(meanWage = mean(wage)) # make new tibble that has mean wage for each level of sex, you will only have two columns/variables in this tibble 1) sex and 2) meanWage
# create more than 1 summary variable
CPS85 %>% 
  group_by(sex) %>% 
  summarize(meanWage = mean(wage),
            n = n()) # n() is the count function, very helpful for most summaries ## will count total observations for your variable meanWage


```


Example d: if you want to run all 5 summaries (which you should), use `fivenum()` function

```{r other summaries}

## Option 1: summaries for entire tibble (men and women included)
CPS85 %>%
  .$wage %>% # select one column/vector of information you want to summarize
  fivenum() # run all 5 summary statistics


## Option 2: summaries broken down for each sex (more appropriate of comparisons!)
CPS85 %>%
  group_by(sex) %>% 
  summarise(n = n(), # count observations
            min = fivenum(wage)[1],
            Q1 = fivenum(wage)[2],
            median = fivenum(wage)[3],
            Q3 = fivenum(wage)[4],
            max = fivenum(wage)[5])


## Option 3: you can also compare multiple variables by group
CPS85 %>% 
  group_by(sector, sex) %>%  # looking at SEX and SECTOR
  summarise(n = n(),
            min = fivenum(wage)[1],
            Q1 = fivenum(wage)[2],
            median = fivenum(wage)[3],
            Q3 = fivenum(wage)[4],
            max = fivenum(wage)[5])
```

### Exercises 

Try to fill in the structure that is provided in the exercises. If you can't figure out the structure, try googling some answers. There are many ways to solve one problem in R. And if you're stuck in google, the answers to the exercises are on the bottom of the document.


1. How many flights occurred on April 18th? 
```{r}

## HINT: use the structure I have provided below, fill in the appropriate DATASET, VARIABLE, FUNCTION you are wrangling

# DATASET %>%
#   FUNCTION(VARIABLE == 4 & VARIABLE == 18) %>%
#   nrow()

```


2. Count the number of flights that left (departures) individual airports (origin).

```{r}

## HINT: use the structure I have provided below, fill in the appropriate DATASET, VARIABLE, FUNCTION you are wrangling

# DATASET %>%
#   filter(!is.na(dep_delay)) %>% # remove NAs
#   group_by(VARIABLE1) %>% # where are flights taking off
#   summarise(VARIABLE2 = n()) # count how many flights left


```


3. CHALLENGE: Count the number of flights that left individual airports AND create a new column that calculates the mean departure delay.

```{r}

## HINT: same as exercise 2 but now you are adding an additional summarise() argument

# dataset %>%
#   filter(!is.na(dep_delay)) %>% # remove NAs
#   group_by(VARIABLE1) %>% # where are flights taking off
#   summarise(VARIABLE2 = n(),
#     meanDelay = FUNCTION(dep_lay)) # creating new column called 'meanDelay'


```


### Google is your friend


I cannot emphasize enough that as a coder, you don't need to memorize anything. Personally as a coder, I rarely code without having google or my github open. R is great because there is a vast community of coders from all levels who are eager to help - so utilize those resources!

Some tips for when you are googling:

+ use language that the R community is familiary with. Instead of using the actual names from your dataset, describe things as variables, rows, columns, datasets, etc.

+ start basic and then expand your search. Maybe start with 'How to select rows' and then 'How to select rows by multiple variables'. The simpler search may lead you to more internet threads. 

+ use tag words for your search such as: R, tidyverse, ggplot or other package and library names. So you would ask 'How to select rows in R using tidyverse'

+ Recommend help platforms like Stack Overflow, Datanovia, R cheatsheets 


### Exercise answers (it's okay we've all been there)

Exercise 1 answer

```{r}
flights %>%
  filter(month == 4 & day == 18) %>%
  nrow()
```


Exercise 2 answer

```{r}
flights %>% 
  filter(!is.na(dep_delay)) %>% 
  group_by(origin) %>%
  summarise(departures = n())

```

Exercise 3 answer

```{r}
flights %>% 
  filter(!is.na(dep_delay)) %>% 
  group_by(origin) %>%
  summarise(departures = n(),
            meanDelay = mean(dep_delay))
```



